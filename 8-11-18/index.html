<!DOCTYPE html><html><head><meta charset="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><link rel="preload" href="/component---src-layouts-index-js-1ce5ce13192bc9f3d480.js" as="script"/><link rel="preload" href="/component---src-templates-post-js-6733a8c7c9321ecca64a.js" as="script"/><link rel="preload" href="/path---8-11-18-7df658a9186d8d68f880.js" as="script"/><link rel="preload" href="/app-c3d993ab6e1bba535f10.js" as="script"/><link rel="preload" href="/commons-b28cb5a1a06ec3a0e088.js" as="script"/><title data-react-helmet="true">Crandallogs</title><meta data-react-helmet="true" name="description" content="David Crandall"/><meta data-react-helmet="true" name="keywords" content="David Crandall"/><style id="gatsby-inlined-css">html{font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}body{margin:0;overflow-x:hidden}article,aside,details,figcaption,figure,footer,header,main,menu,nav,section,summary{display:block}audio,canvas,progress,video{display:inline-block}audio:not([controls]){display:none;height:0}progress{vertical-align:baseline}[hidden],template{display:none}a{background-color:transparent;-webkit-text-decoration-skip:objects}a:active,a:hover{outline-width:0}abbr[title]{border-bottom:none;text-decoration:underline;text-decoration:underline dotted}b,strong{font-weight:inherit;font-weight:bolder}dfn{font-style:italic}h1{font-size:2em;margin:.67em 0}mark{background-color:#ff0;color:#000}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}img{border-style:none}svg:not(:root){overflow:hidden}code,kbd,pre,samp{font-family:monospace,monospace;font-size:1em}figure{margin:1em 40px}hr{box-sizing:content-box;height:0;overflow:visible}button,input,optgroup,select,textarea{font:inherit;margin:0}optgroup{font-weight:700}button,input{overflow:visible}button,select{text-transform:none}[type=reset],[type=submit],button,html [type=button]{-webkit-appearance:button}[type=button]::-moz-focus-inner,[type=reset]::-moz-focus-inner,[type=submit]::-moz-focus-inner,button::-moz-focus-inner{border-style:none;padding:0}[type=button]:-moz-focusring,[type=reset]:-moz-focusring,[type=submit]:-moz-focusring,button:-moz-focusring{outline:1px dotted ButtonText}fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}legend{box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal}textarea{overflow:auto}[type=checkbox],[type=radio]{box-sizing:border-box;padding:0}[type=number]::-webkit-inner-spin-button,[type=number]::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}[type=search]::-webkit-search-cancel-button,[type=search]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-input-placeholder{color:inherit;opacity:.54}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}html{font:112.5%/1.45em georgia,serif;box-sizing:border-box;overflow-y:scroll}*,:after,:before{box-sizing:inherit}body{color:rgba(0,0,0,.8);font-family:georgia,serif;font-weight:400;word-wrap:break-word;font-kerning:normal;-moz-font-feature-settings:"kern","liga","clig","calt";-ms-font-feature-settings:"kern","liga","clig","calt";-webkit-font-feature-settings:"kern","liga","clig","calt";font-feature-settings:"kern","liga","clig","calt"}img{max-width:100%;margin:0 0 1.45rem;padding:0}h1{font-size:2.25rem}h1,h2{margin:0 0 1.45rem;padding:0;color:inherit;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen,Ubuntu,Cantarell,Fira Sans,Droid Sans,Helvetica Neue,sans-serif;font-weight:700;text-rendering:optimizeLegibility;line-height:1.1}h2{font-size:1.62671rem}h3{font-size:1.38316rem}h3,h4{margin:0 0 1.45rem;padding:0;color:inherit;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen,Ubuntu,Cantarell,Fira Sans,Droid Sans,Helvetica Neue,sans-serif;font-weight:700;text-rendering:optimizeLegibility;line-height:1.1}h4{font-size:1rem}h5{font-size:.85028rem}h5,h6{margin:0 0 1.45rem;padding:0;color:inherit;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen,Ubuntu,Cantarell,Fira Sans,Droid Sans,Helvetica Neue,sans-serif;font-weight:700;text-rendering:optimizeLegibility;line-height:1.1}h6{font-size:.78405rem}hgroup{margin:0 0 1.45rem;padding:0}ol,ul{margin:0 0 1.45rem 1.45rem;padding:0;list-style-position:outside;list-style-image:none}dd,dl,figure,p{margin:0 0 1.45rem;padding:0}pre{padding:0;font-size:.85rem;line-height:1.42;background:rgba(0,0,0,.04);border-radius:3px;overflow:auto;word-wrap:normal;padding:1.45rem}pre,table{margin:0 0 1.45rem}table{padding:0;font-size:1rem;line-height:1.45rem;border-collapse:collapse;width:100%}fieldset{margin:0 0 1.45rem;padding:0}blockquote{margin:0 1.45rem 1.45rem;padding:0;padding:0 1em;color:#6a737d;border-left:.25em solid #dfe2e5}form,iframe,noscript{margin:0 0 1.45rem;padding:0}hr{margin:0 0 calc(1.45rem - 1px);padding:0;background:rgba(0,0,0,.2);border:none;height:1px}address{margin:0 0 1.45rem;padding:0}b,dt,strong,th{font-weight:700}li{margin-bottom:0.725rem}ol li,ul li{padding-left:0}li>ol,li>ul{margin-left:1.45rem;margin-bottom:0.725rem;margin-top:0.725rem}blockquote :last-child,li :last-child,p :last-child{margin-bottom:0}li>p{margin-bottom:0.725rem}code,kbd,samp{font-size:.85rem;line-height:1.45rem}abbr,abbr[title],acronym{border-bottom:1px dotted rgba(0,0,0,.5);cursor:help}abbr[title]{text-decoration:none}td,th,thead{text-align:left}td,th{border-bottom:1px solid rgba(0,0,0,.12);font-feature-settings:"tnum";-moz-font-feature-settings:"tnum";-ms-font-feature-settings:"tnum";-webkit-font-feature-settings:"tnum";padding:.725rem .96667rem calc(.725rem - 1px)}td:first-child,th:first-child{padding-left:0}td:last-child,th:last-child{padding-right:0}code,tt{background-color:rgba(0,0,0,.04);border-radius:3px;font-family:SFMono-Regular,Consolas,Roboto Mono,Droid Sans Mono,Liberation Mono,Menlo,Courier,monospace;padding:0;padding-top:.2em;padding-bottom:.2em;margin-right:.2rem}pre code{background:none;line-height:1.42}code:after,code:before,tt:after,tt:before{letter-spacing:-.2em;content:" "}pre code:after,pre code:before,pre tt:after,pre tt:before{content:""}@media only screen and (max-width:480px){html{font-size:100%}}.markdown h1,.markdown h2{color:#484d53}.markdown h3{color:#1d669b;font-weight:400}code[class*=language-],pre[class*=language-]{color:#f8f8f2;background:none;text-shadow:0 1px rgba(0,0,0,.3);font-family:Consolas,Monaco,Andale Mono,Ubuntu Mono,monospace;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-ms-hyphens:none;hyphens:none}pre[class*=language-]{padding:1em;margin:.5em 0;overflow:auto;border-radius:.3em}:not(pre)>code[class*=language-],pre[class*=language-]{background:#272822}:not(pre)>code[class*=language-]{padding:.1em;border-radius:.3em;white-space:normal}.token.cdata,.token.comment,.token.doctype,.token.prolog{color:#708090}.token.punctuation{color:#f8f8f2}.namespace{opacity:.7}.token.constant,.token.deleted,.token.property,.token.symbol,.token.tag{color:#f92672}.token.boolean,.token.number{color:#ae81ff}.token.attr-name,.token.builtin,.token.char,.token.inserted,.token.selector,.token.string{color:#a6e22e}.language-css .token.string,.style .token.string,.token.entity,.token.operator,.token.url,.token.variable{color:#f8f8f2}.token.atrule,.token.attr-value,.token.class-name,.token.function{color:#e6db74}.token.keyword{color:#66d9ef}.token.important,.token.regex{color:#fd971f}.token.bold,.token.important{font-weight:700}.token.italic{font-style:italic}.token.entity{cursor:help}</style></head><body><div id="___gatsby"><div data-reactroot="" data-reactid="1" data-react-checksum="-201523232"><!-- react-empty: 2 --><div class="sc-bdVaJa jgmomP" data-reactid="3"><div class="sc-bwzfXH igxhyw" data-reactid="4"><h2 style="margin:0;" data-reactid="5"><a style="color: #6f7477;align-self:center;text-decoration:none;" aria-current="false" href="/" data-reactid="6"><!-- react-text: 7 -->Crandal<!-- /react-text --><span style="color:rgb(35,40,45);" data-reactid="8">logs</span></a></h2><ul class="sc-htpNat XYWML" data-reactid="9"><li data-reactid="10"><a aria-current="false" href="/blog" data-reactid="11">Blog</a></li><li data-reactid="12"><a href="https://dcrands.com" data-reactid="13">Portfolio</a></li><li data-reactid="14"><a href="https://github.com/dacrands" data-reactid="15">Github</a></li></ul></div></div><div style="margin:0 auto;max-width:960px;padding:0px 1.0875rem 1.45rem;padding-top:0;" data-reactid="16"><div class="markdown" style="padding-bottom:1.45rem;max-width:600px;margin:0 auto;" data-reactid="17"><h1 data-reactid="18">Revisiting Python Data Visualization</h1><ul class="sc-dnqmqq gBCurU" data-reactid="19"><li class="sc-iwsKbI eJmZhq" data-reactid="20">Python</li><li class="sc-iwsKbI eJmZhq" data-reactid="21">Matplotlib</li><li class="sc-iwsKbI eJmZhq" data-reactid="22">Data Visualization</li><li class="sc-iwsKbI eJmZhq" data-reactid="23">Jupyter Notebooks</li></ul><div data-reactid="24"><h2>Background</h2>
<hr>
<h3><em>tl;dr The graphs I made for my undergraduate research posters stunk, so I started to program to get better at visualizing data.</em></h3>
<p>The whole reason I got started with programming is because I wanted to make nice graphs. As an undergrad I was heavily involved in research, which means I used to have to visualize data for poster presentations. At first, I had zero knowledge of data visualization tools outside of what came with SPSS, PowerPoint, and Excel. Consequently, the graphs on my posters were always drab and uninteresting.</p>
<p><img src="https://www.biostat.wisc.edu/~kbroman/topten_worstgraphs/epstein_fig1.jpg" alt="example of a bad graph"></p>
<p>I remember being at a symposium, standing there with my terrible SPSS histograms, and overhearing a conversation between a grad student and a professor. The former said how one of her research assistants makes amazing graphs with matlab. The professor was immediately intrigued and impressed by this, and, to the best of my recollection, began inquiring as to ways to find such students. This had a lasting impact on me, though I wouldn't start to program until years later (It's a long story).</p>
<h2>Learning Path</h2>
<hr>
<p>I will not go through an in-depth rundown of my learning path here, but these were the first resources I used to learn programming:</p>
<ul>
<li>
<p><strong>Reddit</strong> (e.g., r/learnpython, r/python)</p>
<p>This remains my post important tool for learning to program.
I check reddit constantly to stay up to date with the industry.</p>
</li>
</ul>
<ul>
<li>
<p><strong>Automate the Boring Stuff (ATBS)</strong></p>
<p>I can't reccommned ATBS enough. It will teach you the basics and have you doing some cool things very quickly. Though I never completed the book, the first few chapters were very informative and well-presented. This is no surprise, as ATBS is perhaps the most highly recommended resource for getting started with Python.</p>
</li>
<li>
<p><strong>$10 udemy course on Python Data Visualization</strong></p>
<p>I won't mention the course here since it has not been updated in quite some time and it wasn't super great (free resources are easily as good), but it did get me started with the hallmark data-science libraries.
I began this course once I had a pretty solid understanding of the fundamentals and OOP. It taught me the basics of <strong>numpy</strong>, <strong>pandas</strong>, and <strong>seaborn,</strong> but most of my learning these libraries came directly from the documentation and <em>stackoverflow</em> questions. Also, there is only so much you can do with seaborn before you need to dive directly into matplotlib.</p>
</li>
</ul>
<p>Now I'm going to fast-forward a bit, but here are some takeaways from my experience of going from zero programming knowledge to reading, cleaning and visualizing data with Python:</p>
<ul>
<li>
<p><strong>Visualizing data requires a strong understanding of basic data manipulation.</strong> </p>
<p>Before you can get up and running with the Seaborn and Matplotlib to make pretty graphs, you'll need to get a strong understanding of Numpy and Pandas. This, in turn, requires a strong understanding of data-objects and tools, e.g., matrices, dataframes, pivot tables, and the ability slice and manipulate said objects for analysis.</p>
</li>
<li>
<p><strong>Use Conda and Jupyter Notebooks</strong>. </p>
<p>If you are not familiar with Conda or Jupyter Noteboks, I suggest you look into them. Conda makes working with packages and virtual environments very easy. Jupyter Notebooks allow you run code in snippets in Google Chrome without having to boot up an IDE. I will not go into the the complete awesomeness of Jupyter Notebooks and Conda here, but I really enjoy working with them.</p>
</li>
<li>
<p><strong>Use virtual environments.</strong> </p>
<p>It's better to get familiar with virtual environments sooner rather than later, especially since some really awesome data libraries, such as word-cloud, rely on earlier versions of libraries such as Numpy. </p>
<p>Virtual environments are particularly easy to set up with Conda, though there are some issues when using them on Windows, so be careful. I suggest using the Command Prompt and not PowerShell when using virtual environments on Windows, since the former will indicate whether the env is active or not.</p>
<p>For example:</p>
<div class="gatsby-highlight" data-language="text">
      <pre class="language-text"><code class="language-text">:: command prompt
C:\Users\dacrands&gt;activate wordcloudenv
(wordcloudenv) C:\Users\dacrands&gt;</code></pre>
      </div>
<p>vs.</p>
<div class="gatsby-highlight" data-language="text">
      <pre class="language-text"><code class="language-text">:: PowerShell
C:\Users\dacrands&gt;activate wordcloudenv
C:\Users\dacrands&gt;</code></pre>
      </div>
</li>
</ul>
<br />
<h2>My First Data Project</h2>
<hr>
<p><img src="https://github.com/dacrands/ww1WikiGraphs/raw/master/mili-graph.png" alt="WW1 military casualties graph">
<img src="https://github.com/dacrands/ww1WikiGraphs/raw/master/civi-graph.png" alt="WW1 civilian casualties graph"></p>
<p>This project will always have a special place in my heart. It was the first time in my programming journey when I envisioned something that would be really cool to make and actually made it. Of course the dataset was extremely small, but it didn't matter. I took data and visualized it using Python, I achieved one of my dreams! I did something that potentially would have impressed that professor I never actully met from years earlier!</p>
<p>Anyway, the data for this project was taken from a Wikipedia table, which was incredibly easy to scrape using Pandas, although the data was in pretty rough shape.</p>
<h3>The Regex</h3>
<p>The data from the table came in a strange string (e.g, <em>"56,639[18] to 64,996 [9]"</em>, <em>"1,700,000[33] to 2,254,369[51]"</em>) when I needed integers, thus I employed some regex magic. I created a function to grab the lower estimates of the data (i.e., <em>56,639</em> instead of <em>64,996</em>): </p>
<div class="gatsby-highlight" data-language="python">
      <pre class="language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">column_cleaner</span><span class="token punctuation">(</span>arr<span class="token punctuation">)</span><span class="token punctuation">:</span>    
    <span class="token triple-quoted-string string">"""
    In: array of strs containing numerical characters delimited by commas and
    NaN values (i.e., a Wikipedia table column)
    Out: array of ints
    """</span>    
    newList <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> arr<span class="token punctuation">:</span>
        <span class="token keyword">if</span> <span class="token builtin">type</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span> <span class="token keyword">is</span> <span class="token builtin">str</span><span class="token punctuation">:</span>
            newList<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span>re<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>r<span class="token string">'\d{2,}'</span><span class="token punctuation">)</span>
              <span class="token punctuation">.</span>search<span class="token punctuation">(</span>i<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">','</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
              <span class="token punctuation">.</span>group<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            newList<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> newList</code></pre>
      </div>
<p><em>Yes, I know this function isn't very good as there is no error handling, etc., but I was young and it works.</em></p>
<p>Now let's take a look at the data so we can see this super cool function in action.</p>
<h3>The Data</h3>
<p>As I mentioned, Pandas made grabbing the data very easy.</p>
<div class="gatsby-highlight" data-language="python">
      <pre class="language-python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd

ww1_data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_html<span class="token punctuation">(</span><span class="token string">'https://en.wikipedia.org/wiki/World_War_I_casualties'</span><span class="token punctuation">)</span>
dframe <span class="token operator">=</span> DataFrame<span class="token punctuation">(</span>ww1_data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre>
      </div>
<p><img src="https://i.imgur.com/cGD5VTk.jpg" alt="WW1 wikipedia table"></p>
<p>That's it! I believe pandas is grabbing the innerHTML of the table, in the process turning things like <em>a</em> tags into
plain strings.
So now that we have the data, it's just a matter of cleaning things up.</p>
<p><strong>First,</strong> let's rename our columns to something a bit less verbose.</p>
<div class="gatsby-highlight" data-language="python">
      <pre class="language-python"><code class="language-python">dframe <span class="token operator">=</span> dframe<span class="token punctuation">.</span>rename<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token punctuation">{</span>
                              <span class="token number">0</span><span class="token punctuation">:</span> <span class="token string">'countries'</span><span class="token punctuation">,</span>
                              <span class="token number">1</span><span class="token punctuation">:</span> <span class="token string">'pop'</span><span class="token punctuation">,</span>
                              <span class="token number">2</span><span class="token punctuation">:</span> <span class="token string">'dead/MIA'</span><span class="token punctuation">,</span>
                              <span class="token number">3</span><span class="token punctuation">:</span> <span class="token string">'allDead'</span><span class="token punctuation">,</span>
                              <span class="token number">4</span><span class="token punctuation">:</span> <span class="token string">'civisDead'</span><span class="token punctuation">,</span>
                              <span class="token number">5</span><span class="token punctuation">:</span> <span class="token string">'civisIndirectDead'</span><span class="token punctuation">,</span>
                              <span class="token number">6</span><span class="token punctuation">:</span> <span class="token string">'TotDeaths'</span><span class="token punctuation">,</span>
                              <span class="token number">7</span><span class="token punctuation">:</span> <span class="token string">'DeadPop%'</span><span class="token punctuation">,</span>
                              <span class="token number">8</span><span class="token punctuation">:</span> <span class="token string">'miliWounded'</span>
                            <span class="token punctuation">}</span><span class="token punctuation">)</span></code></pre>
      </div>
<br />
<p><img src="https://i.imgur.com/OrJ2ocb.png" alt="Clean graph&#x27;s columns">
You may have noticed that the dataframe is transposed.
I did this several times throughout the project because, at least at the time,
this made indexing and renaming columns much easier.</p>
<p><strong>Second,</strong> let's use that function I mentioned earlier to convert these messy strings into some nice integers.</p>
<div class="gatsby-highlight" data-language="python">
      <pre class="language-python"><code class="language-python">  <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">'dead/MIA'</span><span class="token punctuation">,</span> <span class="token string">'allDead'</span><span class="token punctuation">,</span> <span class="token string">'civisDead'</span><span class="token punctuation">,</span> <span class="token string">'civisIndirectDead'</span><span class="token punctuation">,</span> <span class="token string">'TotDeaths'</span><span class="token punctuation">,</span> <span class="token string">'miliWounded'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
    power_frame<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> column_cleaner<span class="token punctuation">(</span>power_frame<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre>
      </div>
<p><em>Note: we are only doing this for select columns</em></p>
<p>I'll show the <em>dramatic</em> results of this function below.</p>
<p><strong>Third,</strong> the table contained data for 30 countries, when I only wanted to look at a select few. Here's how I created a new data-frame containing only the countries I was interested in: </p>
<div class="gatsby-highlight" data-language="python">
      <pre class="language-python"><code class="language-python">power_frame <span class="token operator">=</span> dframe<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">21</span><span class="token punctuation">,</span><span class="token number">14</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">24</span><span class="token punctuation">,</span><span class="token number">12</span><span class="token punctuation">,</span><span class="token number">19</span><span class="token punctuation">,</span><span class="token number">26</span><span class="token punctuation">,</span><span class="token number">27</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
power_frame<span class="token punctuation">[</span><span class="token string">'countries'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span>
                      <span class="token string">'USA'</span><span class="token punctuation">,</span>
                      <span class="token string">'Italy'</span><span class="token punctuation">,</span>
                      <span class="token string">'UK'</span><span class="token punctuation">,</span>
                      <span class="token string">'Aus-Hung'</span><span class="token punctuation">,</span>
                      <span class="token string">'France'</span><span class="token punctuation">,</span>
                      <span class="token string">'Russia'</span><span class="token punctuation">,</span>
                      <span class="token string">'Germany'</span><span class="token punctuation">,</span>
                      <span class="token string">'Ottoman'</span>
                    <span class="token punctuation">]</span></code></pre>
      </div>
<p>And that's about it in terms of the data.</p>
<h4>Before...</h4>
<p><img src="https://i.imgur.com/cGD5VTk.jpg" alt="WW1 wikipedia table"></p>
<h4>After...</h4>
<p><img src="https://i.imgur.com/hQph3cX.jpg" alt="Imgur"></p>
<h2>Going Back</h2>
<hr>
<p>I revisited a lot of old code in the writing of this post and it's been, for the most part, a pleasurably nostalgic journey back to the world of Python data-science. Although my intention was to just paste some snippets of code and show the graphs, when writing this I actually booted up a jupyter notebook and began running the scripts I wrote. Thankfully this project still works.</p>
<p><img src="https://i.imgur.com/kNN4Z4J.jpg" alt="new ww1 casualty graph"></p>
<p>My primary reason for revisualizing the data was to see if I still could. Luckily there wasn't much of an issue putting the above barplot together, though I did <em>not</em> miss the matplotlib documentation. Documentation for web development is presented so beautifully and written with character, web devs are truly spoiled in that sense. It makes sense that <em>Stackoverflow</em> answers most of my matplotlib questions, as the library's docs leave a lot to be desired.   </p></div><a href="/blog" data-reactid="25">← Blogs page</a></div></div><button class="sc-htoDjs bSCKvV" style="display:none;" data-reactid="26">Back to Top</button><footer class="sc-bxivhb bIdLYx" data-reactid="27"><a class="sc-ifAKCX lmbMoO" aria-current="false" href="/" data-reactid="28">Home</a><span data-reactid="29">∙</span><a target="_blank" href="https://github.com/dacrands" data-reactid="30">Github</a><span data-reactid="31">∙</span><a target="_blank" href="https://dcrands.com/" data-reactid="32">Portfolio</a><p data-reactid="33">© 2018 by David Crandall. All rights reserved. 🌏</p></footer></div></div><script id="webpack-manifest">/*<![CDATA[*/window.webpackManifest={"231608221292675":"app-c3d993ab6e1bba535f10.js","195351340454287":"component---src-templates-post-js-6733a8c7c9321ecca64a.js","162898551421021":"component---src-pages-404-js-cf325d2e9bf981eec2f6.js","212839066777427":"component---src-pages-blog-js-5912e37dcdeac7c75fc4.js","35783957827783":"component---src-pages-index-js-7cbe450fc8ce87f085d5.js","78997501137040":"component---src-pages-tag-js-b92dabcb6f11dc44086b.js","60335399758886":"path----10f5df7b758436d66fa8.js","204011855927958":"path---8-5-18-2f8133838b691783917a.js","279523809777781":"path---10-6-18-fbc49c157d5a9a64a741.js","128175830392225":"path---8-6-18-181839d574dafb63c603.js","134703551178697":"path---8-11-18-7df658a9186d8d68f880.js","227493892435967":"path---8-9-18-12684389d0c8dde5020e.js","198944226089714":"path---10-7-18-0dbe6fb61a6d586adc09.js","26702724923987":"path---8-18-18-1077d3371177990cc7bf.js","217101936054543":"path---11-21-18-2912522c00755ac3cd9f.js","159838037653641":"path---8-24-18-7388c1dc9341ba18277a.js","246546471107980":"path---8-13-18-a90f028431e6ad5ee179.js","40449485089441":"path---9-27-18-955b948bf41015f7842d.js","161428299739788":"path---1-6-19-277ab5c668c132a640de.js","254022195166212":"path---404-a0e39f21c11f6a62c5ab.js","49683490770531":"path---blog-4e5a3302bc5fed1996cb.js","142629428675168":"path---index-4e5a3302bc5fed1996cb.js","98043277450883":"path---tag-a0e39f21c11f6a62c5ab.js","178698757827068":"path---404-html-a0e39f21c11f6a62c5ab.js","114276838955818":"component---src-layouts-index-js-1ce5ce13192bc9f3d480.js"}/*]]>*/</script><script>
  
  
  if(true) {
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  }
  if (typeof ga === "function") {
    ga('create', 'UA-127816565-2', 'auto', {});
      
      }
      </script><script>/*<![CDATA[*/["/commons-b28cb5a1a06ec3a0e088.js","/app-c3d993ab6e1bba535f10.js","/path---8-11-18-7df658a9186d8d68f880.js","/component---src-templates-post-js-6733a8c7c9321ecca64a.js","/component---src-layouts-index-js-1ce5ce13192bc9f3d480.js"].forEach(function(s){document.write('<script src="'+s+'" defer></'+'script>')})/*]]>*/</script></body></html>